# Advanced Electron Microscopy & Diffraction

This repository contains analysis notebooks and outputs for MATSCI 465 assignments.

## Data Availability

The raw 4D-STEM datasets and other experimental data are located in the `raw_data/` directory.

> **Note:** The `raw_data` folder is hosted in this repository on GitHub. If you are cloning this repository, ensure you have downloaded the full folder contents. Some raw data files (e.g., `.dm4`) can be large; if Git LFS is used, ensure you have pulled the actual files.

## Project Structure

```text
.
├── assignment_01_setup.ipynb         # Week 01: Basic Stats & Intro
├── assignment_02_setup.ipynb         # Week 02: 4D-STEM & Virtual Detectors
├── assignment_04_combined.ipynb      # Week 04: Nanoparticle Analysis (Classical, ML, DL)
├── raw_data/                         # Raw experimental data
│   ├── Si-SiGe.dm4                   # (Required for Assignment 02)
│   ├── Diffraction SI_Au_Calib.dm4   # (Required for Calibration)
│   ├── example_EM_Image.tif          # (Required for Assignment 01)
│   └── 11500X*.png                   # (Required for Assignment 04 DOPAD)
├── assignment_01_output/             # Generated outputs for Week 01
├── assignment_02_output/             # Generated outputs for Week 02
│   ├── data/
│   │   ├── processed/            # Processed data output
│   │   └── raw/                  # Reference raw 4D-STEM datasets
│   │       ├── Diffraction SI_Au_Calib.dm4
│   │       └── Si-SiGe.dm4
│   ├── figures/                  # Final figures
│   │   ├── key_figure_1_virtual_detectors.png  # Virtual detector setup
│   │   ├── key_figure_2_virtual_adf_clean.png  # Cleaned ADF image
│   │   └── key_figure_3_line_profile.png       # Line profile analysis
│   └── src/                      # Source code (if applicable)
├── assignment_04_output/             # Generated outputs for Week 04
│   ├── data/
│   │   ├── deep_learning/        # Generated datasets for DL Tasks 
│   │   │   ├── cnn/              # Image crops for classification (train/val split)
│   │   │   └── unet/             # Full images & masks for segmentation (train/val split)
│   │   ├── processed/            # CSV Results
│   │   │   ├── classical_results.csv
│   │   │   ├── ml_results.csv
│   │   │   └── final_comparison.csv
│   │   └── raw/                  # Reference raw images
│   └── figures/                  # Final figures
│       └── final_panel.png       # Combined visualization of pipeline results
├── environment.yml                   # Conda environment file
├── README.md
└── .gitignore
```

## Environment Details & Installation

The analysis is performed in a dedicated Conda environment named `matsci465`.

**Python Version:** 3.10.19
**Key Libraries:** `py4DSTEM`, `HyperSpy`, `NumPy`, `Matplotlib`, `JupyterLab`, `scikit-image`, `scikit-learn`, `tensorflow`

### Quick Start

1. **Create and activate the environment:**

   ```bash
   conda create -n matsci465 python=3.10 -y
   conda activate matsci465
   ```
2. **Install required packages:**

   ```bash
   conda install -c conda-forge jupyterlab numpy scipy matplotlib hyperspy py4dstem scikit-image scikit-learn -y
   pip install tensorflow
   ```

   *Alternatively, if `environment.yml` is used:*

   ```bash
   conda env create -f environment.yml
   ```
3. **Launch Jupyter Lab:**

   ```bash
   jupyter lab
   ```

---

## Assignments

### Assignment 04: Nanoparticle Detection Pipeline

* **Notebook:** `assignment_04_combined.ipynb`
* **Focus:** Nanoparticle analysis using Classical, Machine Learning, and Deep Learning approaches.

#### Methodology

1. **Classical Image Analysis (Task 1)**

   * **Technique:** Noise reduction (Median Filter), contrast enhancement (CLAHE), Otsu thresholding, Distance Transform, and Watershed segmentation.
   * **Pros:** Fast, explainable, no training data needed.
   * **Cons:** Sensitive to noise, fixed parameters (requires tuning for different conditions).
2. **Machine Learning (Task 2)**

   * **Technique:** Extracted morphological and intensity features (Area, Perimeter, Mean Intensity, etc.) from segmented regions.
   * **Models:** K-Means clustering (unsupervised classification) to identify groups, followed by SVM and Random Forest (supervised) to classify particles.
   * **Outcome:** Successfully classified particle populations with high accuracy (>98%).
3. **Deep Learning (Task 3)**

   * **Technique:** End-to-end learning from pixel data (using masks generated by the Classical pipeline as ground truth).
   * **CNN (Classification):** A custom 2-block CNN trained to classify individual particle crops.
   * **U-Net (Segmentation):** A fully convolutional network trained to perform binary segmentation.
   * **Pros:** Robust to noise, learns complex features, no manual feature engineering necessary.
   * **Cons:** Requires labeled data, computationally expensive.

#### Quantitative Comparison (Observed Results)

| Method                  | Task           | Metric (F1 / Dice) | Notes                                            |
| :---------------------- | :------------- | :----------------- | :----------------------------------------------- |
| **Watershed**     | Segmentation   | N/A                | Baseline for shape extraction                    |
| **SVM**           | Classification | ~0.98              | Linear separation on features                    |
| **Random Forest** | Classification | 1.00               | Feature-based, prone to overfitting if not tuned |
| **CNN**           | Classification | ~0.90              | Learned from 64x64 pixel crops                   |
| **U-Net**         | Segmentation   | ~0.83 (Dice)       | Pixel-wise segmentation accuracy                 |

### Recommendations

* **Use Classical Methods** for rapid prototyping or simple, high-contrast images where speed is critical.
* **Use Random Forest** when you have a good set of extracted features and tabular data; it showed perfect separation on this dataset.
* **Use Deep Learning (U-Net)** for complex segmentation tasks where simple thresholding fails, though it requires more computation and training data.

### Assignment 02: 4D-STEM & Virtual Detectors

* **Notebook:** `assignment_02_setup.ipynb`
* **Virtual Detectors Concept:** 4D-STEM records the full 2D diffraction pattern at every scan position, allowing for "virtual imaging" post-acquisition.

How virtual detectors in 4D-STEM enable post-acquisition “re-playing” of the experiment by redefining detector geometry in software?

In 4D-STEM, the microscope records a complete 2D diffraction pattern at every pixel of the scan, preserving the full angular distribution of scattered electrons rather than integrating them into a single intensity value. Because this rich 4D dataset is stored, users can create "virtual detectors" by defining software masks—such as circles, annuli, or quadrants—over the recorded diffraction patterns to select specific scattering angles. "Re-playing" the experiment involves mathematically integrating the electron counts within these specific masks to reconstruct images as if physical detectors with those geometries had been used. This capability allows a researcher to generate multiple contrast modes, such as Bright Field, Annular Dark Field, or Differential Phase Contrast, from a single exposure. Consequently, signal collection angles can be optimized and new imaging conditions explored post-acquisition without ever needing to rescan the sample.

One of the most powerful features of 4D-STEM is the ability to perform **virtual imaging** post-acquisition. Unlike conventional STEM, where physical detectors (like Bright Field or Annular Dark Field) are fixed in hardware during the experiment, 4D-STEM records the full 2D diffraction pattern at every scan position.

This allows us to "replay" the experiment in software by defining virtual detectors:

* **Method:** By creating digital masks (e.g., circular, annular, or custom shapes) on the diffraction plane, we can integrate the signal falling onto these specific regions.
* **Advantage:** We can generate BF, ADF, or other contrast modes from the exact same dataset long after the microscope session is finished. This allows us to optimize the detector geometry for the specific features of interest without needing to rescan the sample.

**Key Outputs:**

* **Virtual BF & ADF Images:** Reconstructed from the Si/SiGe interface dataset.
* **Diffraction Analysis:** Center of Mass (CoM) calculation and radial intensity profiling.

### Assignment 01: Introduction & Statistics

* **Notebook:** `assignment_01_setup.ipynb`
* **Focus:** Environment verification, data loading, and basic statistical analysis (mean, standard deviation, histograms) of `example_EM_Image.tif`.
